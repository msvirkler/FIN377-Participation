{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset loader\n",
    "from sklearn import datasets\n",
    "\n",
    "# model training and evalutation utilities \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold # this is one way to generate folds\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# toy data\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you should learn/be aware of based on this lecture \n",
    "\n",
    "Key `sklearn` functions:\n",
    "- `train_test_split`\n",
    "- `cross_validate`\n",
    "- Fold generators: `KFold` and `StratifiedKFold`\n",
    "- Scoring functions per last lecture and how to pass to `cross_validate`\n",
    "- How to compare different models by looping over them with `cross_validate`, `GridSearchCV`, or `RandomizedSearchCV` \n",
    "\n",
    "Not covered today but you should check out:\n",
    "- `confusion_matrix` and `classification_report` (helpful to evaluate models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple \"split, train, evaluate\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data with 50% in each set\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.5)\n",
    "\n",
    "# fit the model on one set of data\n",
    "# ignore the model I choose here, its not important what\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X1, y1) # fit on the \"training data\" X1 and  y1\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "y2_model = model.predict(X2) # using X2 (out-of-sample data), predict y2\n",
    "accuracy_score(y2, y2_model) # see how close y2 is to prediction (fraction of all pred that are exactly right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to do k-fold? It's like repeating the above. In pseudo code, it looks like:\n",
    "1. Break the X and y data into $k$ subsamples\n",
    "2. For each subsample, fit the model, predict OOS, score predictions, and save those\n",
    "\n",
    "Ok?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold in Python: The explicit way, and the wrapped way\n",
    "\n",
    "Watch me do the explicit way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "0.9666666666666667\n",
      "0.9333333333333333\n",
      "0.9333333333333333\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# you can take quick notes here, but I'm not going to write this code slow enough to copy\n",
    "# the point here is to illustrate\n",
    "\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5).split(X,y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the wrapper below! We are going to see how to use that function to:\n",
    "- try multiple models\n",
    "- try different sets of X variables\n",
    "- try different ways to specific folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00150013, 0.00058293, 0.00048399, 0.00078201, 0.00090289]),\n",
       " 'score_time': array([0.00406194, 0.00208783, 0.00230408, 0.00262713, 0.00202227]),\n",
       " 'test_score': array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try the function here\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "cross_validate(model,X,y,cv=StratifiedKFold(n_splits=5),scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try here with diff scores\n",
    "cross_validate(model,X,y,cv=5,scoring=['r2','accuracy','f1_macro'])\n",
    "\n",
    "cross_validate(model,X,y,cv=5,scoring=['r2','accuracy','f1_macro']) ['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the metrics it can compute out of the box are here: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "Notice that many of these were discussed in our last lecture!\n",
    "\n",
    "_**Warning/Note:**_ the metric names on that link and what you put in the `scoring` dictionary don't seem to match up.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the `cross_validate` parameters\n",
    "\n",
    "### The model parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.04941082, 0.00284791, 0.00223732, 0.00293207, 0.00345016]),\n",
       " 'score_time': array([0.00488305, 0.00206017, 0.0018518 , 0.00185585, 0.00147772]),\n",
       " 'test_r2': array([0.65, 0.75, 0.75, 0.65, 0.85]),\n",
       " 'test_accuracy': array([0.76666667, 0.83333333, 0.83333333, 0.76666667, 0.9       ]),\n",
       " 'test_f1_macro': array([0.76129582, 0.82949702, 0.82949702, 0.76608187, 0.89974937])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer here\n",
    "cross_validate(linear_model.RidgeClassifier(),X,y,cv=5,scoring=['r2','accuracy','f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linear_model` submodule contains lots of useful alternate options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example:\n",
    "linear_model.Lasso\n",
    "linear_model.Ridge\n",
    "linear_model.LogisticRegression\n",
    "\n",
    "linear_model.LassoCV() # Returns a Lasso (L1 Regularization) linear model with picking the best model by cross validation\n",
    "linear_model.RidgeCV() # Returns a Ridge (L2 Regularization) linear model with picking the best model by cross validation\n",
    "linear_model.LogisticRegressionCV() # return best logit model by CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up models to try\n",
    "models = []\n",
    "models.append(('svc_1', SVC(gamma='auto') ))\n",
    "models.append(('svc_2', SVC(C=5) ))\n",
    "models.append(('neighbor',  KNeighborsClassifier(n_neighbors=1)))\n",
    "\n",
    "# loop and print\n",
    "for name, model in models:\n",
    "    scores = cross_validate(model, X, y, scoring='accuracy')\n",
    "    print('%s: %.3f (%.3f)' % (name.ljust(10), \n",
    "                                   scores['test_score'].mean(), \n",
    "                                   scores['test_score'].std()\n",
    "                                   )\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The X parameter\n",
    "\n",
    "You can loop over Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a smaller X and a bigger X\n",
    "X_small = X[:,:2] # just first two columns\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X3 = poly.fit_transform(X)\n",
    "\n",
    "# set up Xs to try\n",
    "right here!\n",
    "\n",
    "# loop and print\n",
    "right here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xs and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV parameter and folds\n",
    "\n",
    "Just  watch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn \n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links, resoruces, and next week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only two resources needed\n",
    "- sklearn docs are GREAT https://scikit-learn.org/stable/user_guide.html \n",
    "- Python Data Science Handbook (note some module calls are obsolete, so you might need to update code) https://jakevdp.github.io/PythonDataScienceHandbook/index.html\n",
    "\n",
    "Next week:\n",
    "- preprocessing\n",
    "- data transformations\n",
    "- feasture selection\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
